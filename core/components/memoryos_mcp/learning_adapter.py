#!/usr/bin/env python3
"""
MemoryOS MCP - å­¸ç¿’é©é…å™¨
è™•ç†ä¸åŒä¾†æºçš„å­¸ç¿’æ•¸æ“šä¸¦é€²è¡Œé©é…
"""

import asyncio
import json
import logging
import time
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from enum import Enum
import numpy as np
from collections import defaultdict, deque

logger = logging.getLogger(__name__)

class LearningType(Enum):
    """å­¸ç¿’é¡å‹"""
    CLAUDE_INTERACTION = "claude_interaction"
    USER_BEHAVIOR = "user_behavior"
    PERFORMANCE_OPTIMIZATION = "performance_optimization"
    ERROR_CORRECTION = "error_correction"
    CONTEXT_ENHANCEMENT = "context_enhancement"

@dataclass
class LearningData:
    """å­¸ç¿’æ•¸æ“š"""
    id: str
    source: str
    learning_type: LearningType
    data: Dict[str, Any]
    performance_metrics: Dict[str, float]
    timestamp: float
    success: bool = True
    
    def to_dict(self) -> Dict[str, Any]:
        """è½‰æ›ç‚ºå­—å…¸"""
        return asdict(self)

class LearningAdapter:
    """å­¸ç¿’é©é…å™¨"""
    
    def __init__(self, memory_engine, context_manager):
        self.memory_engine = memory_engine
        self.context_manager = context_manager
        self.learning_history = deque(maxlen=1000)
        self.performance_tracker = defaultdict(list)
        self.learning_patterns = defaultdict(dict)
        self.adaptation_rules = {}
        self.is_initialized = False
        
    async def initialize(self):
        """åˆå§‹åŒ–å­¸ç¿’é©é…å™¨"""
        logger.info("ğŸ§  åˆå§‹åŒ– Learning Adapter...")
        
        # è¼‰å…¥é©é…è¦å‰‡
        await self._load_adaptation_rules()
        
        # åˆå§‹åŒ–æ€§èƒ½è¿½è¹¤å™¨
        await self._initialize_performance_tracker()
        
        self.is_initialized = True
        logger.info("âœ… Learning Adapter åˆå§‹åŒ–å®Œæˆ")
    
    async def _load_adaptation_rules(self):
        """è¼‰å…¥é©é…è¦å‰‡"""
        self.adaptation_rules = {
            LearningType.CLAUDE_INTERACTION: {
                "weight": 1.0,
                "adaptation_rate": 0.1,
                "success_threshold": 0.7,
                "features": ["user_satisfaction", "response_time", "context_relevance"]
            },
            LearningType.USER_BEHAVIOR: {
                "weight": 0.8,
                "adaptation_rate": 0.15,
                "success_threshold": 0.6,
                "features": ["interaction_frequency", "preference_consistency", "workflow_efficiency"]
            },
            LearningType.PERFORMANCE_OPTIMIZATION: {
                "weight": 0.9,
                "adaptation_rate": 0.05,
                "success_threshold": 0.8,
                "features": ["response_time", "accuracy", "resource_usage"]
            },
            LearningType.ERROR_CORRECTION: {
                "weight": 1.2,
                "adaptation_rate": 0.2,
                "success_threshold": 0.9,
                "features": ["error_rate", "correction_accuracy", "learning_speed"]
            },
            LearningType.CONTEXT_ENHANCEMENT: {
                "weight": 0.7,
                "adaptation_rate": 0.12,
                "success_threshold": 0.65,
                "features": ["context_relevance", "enhancement_quality", "user_acceptance"]
            }
        }
    
    async def _initialize_performance_tracker(self):
        """åˆå§‹åŒ–æ€§èƒ½è¿½è¹¤å™¨"""
        for learning_type in LearningType:
            self.performance_tracker[learning_type] = []
    
    async def process_interaction(self, interaction_data: Dict[str, Any]):
        """è™•ç†äº¤äº’æ•¸æ“š"""
        try:
            # æå–å­¸ç¿’ç‰¹å¾µ
            features = await self._extract_learning_features(interaction_data)
            
            # è©•ä¼°äº¤äº’è³ªé‡
            quality_score = await self._evaluate_interaction_quality(interaction_data, features)
            
            # æ›´æ–°å­¸ç¿’æ¨¡å¼
            await self._update_learning_patterns(interaction_data, features, quality_score)
            
            # å­˜å„²å­¸ç¿’æ•¸æ“š
            learning_data = LearningData(
                id=f"learning_{int(time.time())}_{hash(str(interaction_data)) % 10000}",
                source="claude_interaction",
                learning_type=LearningType.CLAUDE_INTERACTION,
                data={
                    "interaction": interaction_data,
                    "features": features,
                    "quality_score": quality_score
                },
                performance_metrics={
                    "response_time": interaction_data.get("response_time", 0),
                    "user_satisfaction": interaction_data.get("user_satisfaction", 0),
                    "context_relevance": features.get("context_relevance", 0)
                },
                timestamp=time.time(),
                success=quality_score > 0.5
            )
            
            await self._store_learning_data(learning_data)
            
            logger.debug(f"âœ… è™•ç†äº¤äº’å­¸ç¿’: {learning_data.id} (è³ªé‡: {quality_score:.3f})")
            
        except Exception as e:
            logger.error(f"âŒ è™•ç†äº¤äº’å­¸ç¿’å¤±æ•—: {e}")
    
    async def _extract_learning_features(self, interaction_data: Dict[str, Any]) -> Dict[str, float]:
        """æå–å­¸ç¿’ç‰¹å¾µ"""
        features = {}
        
        # åŸºæœ¬ç‰¹å¾µ
        features["response_time"] = min(1.0, 5000.0 / max(1.0, interaction_data.get("response_time", 5000)))
        features["user_satisfaction"] = interaction_data.get("user_satisfaction", 0.5)
        features["input_length"] = min(1.0, len(interaction_data.get("user_input", "")) / 1000.0)
        features["output_length"] = min(1.0, len(interaction_data.get("claude_response", "")) / 2000.0)
        
        # ä¸Šä¸‹æ–‡ç‰¹å¾µ
        context_id = interaction_data.get("context_id")
        if context_id:
            context = await self.context_manager.get_context(context_id)
            if context:
                features["context_relevance"] = context.relevance_score
                features["context_age"] = min(1.0, (time.time() - context.created_at) / 3600.0)
        
        # æ­·å²ç‰¹å¾µ
        user_input = interaction_data.get("user_input", "")
        similar_interactions = await self.memory_engine.get_similar_memories(
            content=user_input,
            memory_type=self.memory_engine.MemoryType.CLAUDE_INTERACTION,
            limit=3
        )
        
        if similar_interactions:
            features["similarity_score"] = np.mean([mem.importance_score for mem in similar_interactions])
            features["repetition_factor"] = len(similar_interactions) / 10.0
        else:
            features["similarity_score"] = 0.0
            features["repetition_factor"] = 0.0
        
        return features
    
    async def _evaluate_interaction_quality(self, 
                                          interaction_data: Dict[str, Any], 
                                          features: Dict[str, float]) -> float:
        """è©•ä¼°äº¤äº’è³ªé‡"""
        quality_components = []
        
        # ç”¨æˆ¶æ»¿æ„åº¦ (40%)
        user_satisfaction = interaction_data.get("user_satisfaction", 0.5)
        quality_components.append(user_satisfaction * 0.4)
        
        # éŸ¿æ‡‰æ•ˆç‡ (25%)
        response_efficiency = features.get("response_time", 0.5)
        quality_components.append(response_efficiency * 0.25)
        
        # å…§å®¹ç›¸é—œæ€§ (20%)
        content_relevance = features.get("context_relevance", 0.5)
        quality_components.append(content_relevance * 0.2)
        
        # è¼¸å‡ºè³ªé‡ (15%)
        output_quality = min(1.0, features.get("output_length", 0.5) * 2.0)
        quality_components.append(output_quality * 0.15)
        
        return sum(quality_components)
    
    async def _update_learning_patterns(self, 
                                      interaction_data: Dict[str, Any], 
                                      features: Dict[str, float], 
                                      quality_score: float):
        """æ›´æ–°å­¸ç¿’æ¨¡å¼"""
        user_input = interaction_data.get("user_input", "")
        
        # æå–é—œéµè©
        keywords = self._extract_keywords(user_input)
        
        # æ›´æ–°æ¨¡å¼
        for keyword in keywords:
            if keyword not in self.learning_patterns[LearningType.CLAUDE_INTERACTION]:
                self.learning_patterns[LearningType.CLAUDE_INTERACTION][keyword] = {
                    "count": 0,
                    "total_quality": 0.0,
                    "avg_quality": 0.0,
                    "features": defaultdict(list)
                }
            
            pattern = self.learning_patterns[LearningType.CLAUDE_INTERACTION][keyword]
            pattern["count"] += 1
            pattern["total_quality"] += quality_score
            pattern["avg_quality"] = pattern["total_quality"] / pattern["count"]
            
            # æ›´æ–°ç‰¹å¾µ
            for feature, value in features.items():
                pattern["features"][feature].append(value)
                # ä¿æŒæœ€è¿‘çš„ç‰¹å¾µå€¼
                if len(pattern["features"][feature]) > 20:
                    pattern["features"][feature] = pattern["features"][feature][-20:]
    
    def _extract_keywords(self, text: str) -> List[str]:
        """æå–é—œéµè©"""
        # ç°¡åŒ–çš„é—œéµè©æå–
        words = text.lower().split()
        keywords = []
        
        # ç·¨ç¨‹ç›¸é—œé—œéµè©
        programming_keywords = {
            "python", "javascript", "java", "c++", "html", "css", "sql",
            "react", "vue", "angular", "nodejs", "django", "flask",
            "function", "class", "variable", "loop", "condition",
            "debug", "error", "exception", "test", "api", "database"
        }
        
        for word in words:
            if word in programming_keywords or len(word) > 3:
                keywords.append(word)
        
        return keywords[:10]  # é™åˆ¶é—œéµè©æ•¸é‡
    
    async def record_learning_data(self, 
                                 source: str, 
                                 data: Dict[str, Any], 
                                 learning_type: str, 
                                 timestamp: float):
        """è¨˜éŒ„å­¸ç¿’æ•¸æ“š"""
        try:
            # è½‰æ›å­¸ç¿’é¡å‹
            learning_type_enum = LearningType(learning_type)
            
            # æå–æ€§èƒ½æŒ‡æ¨™
            performance_metrics = data.get("performance_metrics", {})
            
            # å‰µå»ºå­¸ç¿’æ•¸æ“š
            learning_data = LearningData(
                id=f"learning_{int(timestamp)}_{hash(str(data)) % 10000}",
                source=source,
                learning_type=learning_type_enum,
                data=data,
                performance_metrics=performance_metrics,
                timestamp=timestamp,
                success=data.get("success", True)
            )
            
            await self._store_learning_data(learning_data)
            
            # æ›´æ–°æ€§èƒ½è¿½è¹¤
            await self._update_performance_tracker(learning_data)
            
            logger.debug(f"âœ… è¨˜éŒ„å­¸ç¿’æ•¸æ“š: {learning_data.id} ({source})")
            
        except Exception as e:
            logger.error(f"âŒ è¨˜éŒ„å­¸ç¿’æ•¸æ“šå¤±æ•—: {e}")
    
    async def _store_learning_data(self, learning_data: LearningData):
        """å­˜å„²å­¸ç¿’æ•¸æ“š"""
        # æ·»åŠ åˆ°æ­·å²è¨˜éŒ„
        self.learning_history.append(learning_data)
        
        # å­˜å„²åˆ°è¨˜æ†¶å¼•æ“
        memory_id = f"learning_{learning_data.id}"
        
        memory = self.memory_engine.Memory(
            id=memory_id,
            memory_type=self.memory_engine.MemoryType.PROCEDURAL,
            content=json.dumps(learning_data.to_dict()),
            metadata={
                "source": learning_data.source,
                "learning_type": learning_data.learning_type.value,
                "success": learning_data.success,
                "performance_metrics": learning_data.performance_metrics
            },
            created_at=learning_data.timestamp,
            accessed_at=learning_data.timestamp,
            access_count=1,
            importance_score=self._calculate_learning_importance(learning_data),
            tags=["learning", learning_data.learning_type.value, learning_data.source]
        )
        
        await self.memory_engine.store_memory(memory)
    
    def _calculate_learning_importance(self, learning_data: LearningData) -> float:
        """è¨ˆç®—å­¸ç¿’é‡è¦æ€§"""
        base_importance = 0.5
        
        # æˆåŠŸç‡å½±éŸ¿
        if learning_data.success:
            base_importance *= 1.2
        else:
            base_importance *= 0.8
        
        # å­¸ç¿’é¡å‹æ¬Šé‡
        type_weight = self.adaptation_rules.get(learning_data.learning_type, {}).get("weight", 1.0)
        base_importance *= type_weight
        
        # æ€§èƒ½æŒ‡æ¨™å½±éŸ¿
        performance_avg = np.mean(list(learning_data.performance_metrics.values())) if learning_data.performance_metrics else 0.5
        base_importance *= (0.5 + performance_avg * 0.5)
        
        return min(2.0, max(0.1, base_importance))
    
    async def _update_performance_tracker(self, learning_data: LearningData):
        """æ›´æ–°æ€§èƒ½è¿½è¹¤å™¨"""
        tracker = self.performance_tracker[learning_data.learning_type]
        
        # æ·»åŠ æ€§èƒ½æ•¸æ“š
        tracker.append({
            "timestamp": learning_data.timestamp,
            "success": learning_data.success,
            "metrics": learning_data.performance_metrics,
            "importance": self._calculate_learning_importance(learning_data)
        })
        
        # ä¿æŒæœ€è¿‘çš„æ€§èƒ½æ•¸æ“š
        if len(tracker) > 100:
            self.performance_tracker[learning_data.learning_type] = tracker[-100:]
    
    async def get_best_practices(self, query: str, domain: str = "general") -> List[Dict[str, Any]]:
        """ç²å–æœ€ä½³å¯¦è¸"""
        try:
            # æœç´¢ç›¸é—œçš„å­¸ç¿’è¨˜æ†¶
            learning_memories = await self.memory_engine.search_memories(
                query=query,
                memory_type=self.memory_engine.MemoryType.PROCEDURAL,
                tags=["learning"],
                limit=10
            )
            
            best_practices = []
            
            for memory in learning_memories:
                try:
                    learning_data = json.loads(memory.content)
                    
                    # éæ¿¾æˆåŠŸçš„å­¸ç¿’æ•¸æ“š
                    if learning_data.get("success", False):
                        performance_metrics = learning_data.get("performance_metrics", {})
                        
                        # è¨ˆç®—å¯¦è·µè³ªé‡
                        quality_score = np.mean(list(performance_metrics.values())) if performance_metrics else 0.5
                        
                        if quality_score > 0.6:
                            best_practices.append({
                                "id": memory.id,
                                "content": learning_data.get("data", {}).get("interaction", {}).get("claude_response", "")[:200],
                                "quality_score": quality_score,
                                "domain": domain,
                                "tags": memory.tags,
                                "timestamp": memory.created_at
                            })
                            
                except Exception as e:
                    logger.warning(f"è§£æå­¸ç¿’æ•¸æ“šå¤±æ•—: {e}")
                    continue
            
            # æŒ‰è³ªé‡æ’åº
            best_practices.sort(key=lambda x: x["quality_score"], reverse=True)
            
            return best_practices[:5]
            
        except Exception as e:
            logger.error(f"âŒ ç²å–æœ€ä½³å¯¦è¸å¤±æ•—: {e}")
            return []
    
    async def get_learning_statistics(self) -> Dict[str, Any]:
        """ç²å–å­¸ç¿’çµ±è¨ˆ"""
        try:
            stats = {
                "total_learning_records": len(self.learning_history),
                "success_rate": 0.0,
                "avg_response_time": 0.0,
                "context_enhancement_rate": 0.0,
                "avg_user_satisfaction": 0.0,
                "learning_type_distribution": {},
                "performance_trends": {}
            }
            
            if self.learning_history:
                # æˆåŠŸç‡
                successful_records = [ld for ld in self.learning_history if ld.success]
                stats["success_rate"] = len(successful_records) / len(self.learning_history)
                
                # å¹³å‡éŸ¿æ‡‰æ™‚é–“
                response_times = [ld.performance_metrics.get("response_time", 0) for ld in self.learning_history]
                stats["avg_response_time"] = np.mean(response_times) if response_times else 0.0
                
                # å¹³å‡ç”¨æˆ¶æ»¿æ„åº¦
                satisfactions = [ld.performance_metrics.get("user_satisfaction", 0) for ld in self.learning_history]
                stats["avg_user_satisfaction"] = np.mean(satisfactions) if satisfactions else 0.0
                
                # å­¸ç¿’é¡å‹åˆ†ä½ˆ
                for learning_data in self.learning_history:
                    type_name = learning_data.learning_type.value
                    stats["learning_type_distribution"][type_name] = stats["learning_type_distribution"].get(type_name, 0) + 1
                
                # ä¸Šä¸‹æ–‡å¢å¼·ç‡
                enhanced_count = sum(1 for ld in self.learning_history 
                                   if ld.data.get("interaction", {}).get("context_enhanced", False))
                stats["context_enhancement_rate"] = enhanced_count / len(self.learning_history)
            
            # æ€§èƒ½è¶¨å‹¢
            for learning_type, tracker in self.performance_tracker.items():
                if tracker:
                    recent_performance = tracker[-10:]  # æœ€è¿‘10å€‹è¨˜éŒ„
                    stats["performance_trends"][learning_type.value] = {
                        "recent_success_rate": np.mean([p["success"] for p in recent_performance]),
                        "trend_direction": "up" if len(recent_performance) > 5 else "stable"
                    }
            
            return stats
            
        except Exception as e:
            logger.error(f"âŒ ç²å–å­¸ç¿’çµ±è¨ˆå¤±æ•—: {e}")
            return {}
    
    async def optimize_learning_parameters(self):
        """å„ªåŒ–å­¸ç¿’åƒæ•¸"""
        try:
            logger.info("ğŸ”§ å„ªåŒ–å­¸ç¿’åƒæ•¸...")
            
            # åˆ†æå­¸ç¿’æ¨¡å¼
            for learning_type, patterns in self.learning_patterns.items():
                if not patterns:
                    continue
                
                # ç²å–é©é…è¦å‰‡
                rules = self.adaptation_rules.get(learning_type, {})
                
                # è¨ˆç®—å¹³å‡æ€§èƒ½
                avg_quality = np.mean([pattern["avg_quality"] for pattern in patterns.values()])
                
                # èª¿æ•´é©é…ç‡
                if avg_quality > rules.get("success_threshold", 0.7):
                    # æ€§èƒ½è‰¯å¥½ï¼Œé™ä½é©é…ç‡
                    rules["adaptation_rate"] = max(0.01, rules["adaptation_rate"] * 0.95)
                else:
                    # æ€§èƒ½ä¸ä½³ï¼Œæé«˜é©é…ç‡
                    rules["adaptation_rate"] = min(0.5, rules["adaptation_rate"] * 1.05)
                
                logger.debug(f"ğŸ“Š èª¿æ•´ {learning_type.value} é©é…ç‡: {rules['adaptation_rate']:.4f}")
            
            logger.info("âœ… å­¸ç¿’åƒæ•¸å„ªåŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ å„ªåŒ–å­¸ç¿’åƒæ•¸å¤±æ•—: {e}")
    
    async def cleanup(self):
        """æ¸…ç†è³‡æº"""
        self.learning_history.clear()
        self.performance_tracker.clear()
        self.learning_patterns.clear()
        logger.info("ğŸ§¹ Learning Adapter æ¸…ç†å®Œæˆ")

# æ¸¬è©¦å‡½æ•¸
async def main():
    """æ¸¬è©¦å­¸ç¿’é©é…å™¨"""
    print("ğŸ§ª æ¸¬è©¦ Learning Adapter...")
    
    # æ¨¡æ“¬ä¾è³´
    class MockMemoryEngine:
        class MemoryType:
            CLAUDE_INTERACTION = "claude_interaction"
            PROCEDURAL = "procedural"
        
        class Memory:
            def __init__(self, **kwargs):
                for k, v in kwargs.items():
                    setattr(self, k, v)
        
        async def get_similar_memories(self, content, memory_type, limit):
            return []
        
        async def store_memory(self, memory):
            return True
        
        async def search_memories(self, query, memory_type, tags, limit):
            return []
    
    class MockContextManager:
        async def get_context(self, context_id):
            return None
    
    # å‰µå»ºæ¸¬è©¦å¯¦ä¾‹
    memory_engine = MockMemoryEngine()
    context_manager = MockContextManager()
    
    adapter = LearningAdapter(memory_engine, context_manager)
    await adapter.initialize()
    
    # æ¸¬è©¦äº¤äº’è™•ç†
    test_interaction = {
        "user_input": "å¦‚ä½•ä½¿ç”¨ Python é€²è¡Œæ•¸æ“šåˆ†æï¼Ÿ",
        "claude_response": "Python æ•¸æ“šåˆ†æå¯ä»¥ä½¿ç”¨ pandasã€numpy ç­‰åº«...",
        "response_time": 2500,
        "user_satisfaction": 0.85,
        "context_id": "test_context"
    }
    
    await adapter.process_interaction(test_interaction)
    
    # æ¸¬è©¦çµ±è¨ˆ
    stats = await adapter.get_learning_statistics()
    print(f"ğŸ“Š å­¸ç¿’çµ±è¨ˆ: {stats}")
    
    await adapter.cleanup()
    print("âœ… æ¸¬è©¦å®Œæˆ")

if __name__ == "__main__":
    asyncio.run(main())